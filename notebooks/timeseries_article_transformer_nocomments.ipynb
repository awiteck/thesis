{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from torch import nn, Tensor\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dropout: float=0.1, \n",
    "        max_seq_len: int=5000, \n",
    "        d_model: int=512,\n",
    "        batch_first: bool=False\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batch_first = batch_first\n",
    "        self.x_dim = 1 if batch_first else 0\n",
    "\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[:x.size(self.x_dim)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "        input_size: int,\n",
    "        dec_seq_len: int,\n",
    "        batch_first: bool,\n",
    "        out_seq_len: int=58,\n",
    "        dim_val: int=512,  \n",
    "        n_encoder_layers: int=4,\n",
    "        n_decoder_layers: int=4,\n",
    "        n_heads: int=8,\n",
    "        dropout_encoder: float=0.2, \n",
    "        dropout_decoder: float=0.2,\n",
    "        dropout_pos_enc: float=0.1,\n",
    "        dim_feedforward_encoder: int=2048,\n",
    "        dim_feedforward_decoder: int=2048,\n",
    "        num_predicted_features: int=1,\n",
    "        max_seq_len: int=5000\n",
    "        ): \n",
    "\n",
    "        super().__init__() \n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        \n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=input_size, \n",
    "            out_features=dim_val \n",
    "            )\n",
    "\n",
    "        self.decoder_input_layer = nn.Linear(\n",
    "            in_features=num_predicted_features,\n",
    "            out_features=dim_val\n",
    "            )  \n",
    "        \n",
    "        self.linear_mapping = nn.Linear(\n",
    "            in_features=dim_val, \n",
    "            out_features=num_predicted_features\n",
    "            )\n",
    "\n",
    "        self.positional_encoding_layer = PositionalEncoder(\n",
    "            d_model=dim_val,\n",
    "            dropout=dropout_pos_enc\n",
    "            )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_val, \n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_encoder,\n",
    "            dropout=dropout_encoder,\n",
    "            batch_first=batch_first\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=n_encoder_layers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=dim_val,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_decoder,\n",
    "            dropout=dropout_decoder,\n",
    "            batch_first=batch_first\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=decoder_layer,\n",
    "            num_layers=n_decoder_layers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor=None, \n",
    "                tgt_mask: Tensor=None) -> Tensor:\n",
    "\n",
    "        src = self.encoder_input_layer(src) \n",
    "        src = self.positional_encoding_layer(src) \n",
    "        src = self.encoder( \n",
    "            src=src\n",
    "            )\n",
    "        decoder_output = self.decoder_input_layer(tgt) \n",
    "        decoder_output = self.decoder(\n",
    "            tgt=decoder_output,\n",
    "            memory=src,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=src_mask\n",
    "            )\n",
    "        decoder_output = self.linear_mapping(decoder_output) \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model parameters\n",
    "dim_val = 512 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 8 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 4 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
    "input_size = 1 # The number of input variables. 1 if univariate forecasting.\n",
    "dec_seq_len = 92 # length of input given to decoder. Can have any integer value.\n",
    "enc_seq_len = 153 # length of input given to encoder. Can have any integer value.\n",
    "output_sequence_length = 24 # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    dim_val=dim_val,\n",
    "    input_size=input_size, \n",
    "    dec_seq_len=dec_seq_len,\n",
    "    max_seq_len=max_seq_len,\n",
    "    out_seq_len=output_sequence_length, \n",
    "    n_decoder_layers=n_decoder_layers,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    n_heads=n_heads,\n",
    "    batch_first= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_trg(\n",
    "    self,\n",
    "    sequence: torch.Tensor, \n",
    "    enc_seq_len: int, \n",
    "    target_seq_len: int\n",
    "    ):\n",
    "\n",
    "    assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "    src = sequence[:enc_seq_len] \n",
    "    trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "    trg = trg[:, 0]\n",
    "    if len(trg.shape) == 1:\n",
    "        trg = trg.unsqueeze(-1)\n",
    "    assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "    trg_y = sequence[-target_seq_len:]\n",
    "    trg_y = trg_y[:, 0]\n",
    "    assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "    return src, trg, trg_y.squeeze(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(dim1: int, dim2: int) -> Tensor:\n",
    "    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input length\n",
    "enc_seq_len = 100\n",
    "\n",
    "# Make src mask for decoder with size:\n",
    "tgt_mask = generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length,\n",
    "    dim2=output_sequence_length\n",
    "   )\n",
    "\n",
    "src_mask = generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length,\n",
    "    dim2=enc_seq_len\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class used for transformer models.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        data: torch.tensor,\n",
    "        indices: list, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "            data: tensor, the entire train, validation or test data sequence \n",
    "                        before any slicing. If univariate, data.size() will be \n",
    "                        [number of samples, number of variables]\n",
    "                        where the number of variables will be equal to 1 + the number of\n",
    "                        exogenous variables. Number of exogenous variables would be 0\n",
    "                        if univariate.\n",
    "\n",
    "            indices: a list of tuples. Each tuple has two elements:\n",
    "                     1) the start index of a sub-sequence\n",
    "                     2) the end index of a sub-sequence. \n",
    "                     The sub-sequence is split into src, trg and trg_y later.  \n",
    "\n",
    "            enc_seq_len: int, the desired length of the input sequence given to the\n",
    "                     the first layer of the transformer model.\n",
    "\n",
    "            target_seq_len: int, the desired length of the target sequence (the output of the model)\n",
    "\n",
    "            target_idx: The index position of the target variable in data. Data\n",
    "                        is a 2D tensor\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.indices = indices\n",
    "        self.data = data\n",
    "        print(\"From get_src_trg: data size = {}\".format(data.size()))\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple with 3 elements:\n",
    "        1) src (the encoder input)\n",
    "        2) trg (the decoder input)\n",
    "        3) trg_y (the target)\n",
    "        \"\"\"\n",
    "        # Get the first element of the i'th tuple in the list self.indicesasdfas\n",
    "        start_idx = self.indices[index][0]\n",
    "        # Get the second (and last) element of the i'th tuple in the list self.indices\n",
    "        end_idx = self.indices[index][1]\n",
    "        sequence = self.data[start_idx:end_idx]\n",
    "        src, trg, trg_y = self.get_src_trg(\n",
    "            sequence=sequence,\n",
    "            enc_seq_len=self.enc_seq_len,\n",
    "            dec_seq_len=self.dec_seq_len,\n",
    "            target_seq_len=self.target_seq_len\n",
    "            )\n",
    "\n",
    "        return src, trg, trg_y\n",
    "    \n",
    "    def get_src_trg(\n",
    "        self,\n",
    "        sequence: torch.Tensor, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ):\n",
    "\n",
    "        \"\"\"\n",
    "        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n",
    "        sequences from a sequence. \n",
    "\n",
    "        Args:\n",
    "\n",
    "            sequence: tensor, a 1D tensor of length n where \n",
    "                    n = encoder input length + target sequence length  \n",
    "\n",
    "            enc_seq_len: int, the desired length of the input to the transformer encoder\n",
    "\n",
    "            target_seq_len: int, the desired length of the target sequence (the \n",
    "                            one against which the model output is compared)\n",
    "\n",
    "        Return: \n",
    "\n",
    "            src: tensor, 1D, used as input to the transformer model\n",
    "\n",
    "            trg: tensor, 1D, used as input to the transformer model\n",
    "\n",
    "            trg_y: tensor, 1D, the target sequence against which the model output\n",
    "                is compared when computing loss. \n",
    "        \n",
    "        \"\"\"\n",
    "        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "        \n",
    "        # encoder input\n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "        \n",
    "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load your data into a DataFrame\n",
    "# path = \"/Users/aidanwiteck/Desktop/Princeton/Year 4/Thesis/electricgrid/data/final_tables/banc/banc.csv\"\n",
    "# df = pd.read_csv(path)\n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# # Z-score normalization\n",
    "# mean_demand = df['Demand (MWh)'].mean()\n",
    "# std_demand = df['Demand (MWh)'].std()\n",
    "\n",
    "# df['Normalized Demand'] = (df['Demand (MWh)'] - mean_demand) / std_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_entire_sequence(data, window_size: int, step_size: int) -> list:\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions that is needed to produce\n",
    "        the sub-sequences. \n",
    "\n",
    "        Returns a list of tuples. Each tuple is (start_idx, end_idx) of a sub-\n",
    "        sequence. These tuples should be used to slice the dataset into sub-\n",
    "        sequences. These sub-sequences should then be passed into a function\n",
    "        that slices them into input and target sequences. \n",
    "        \n",
    "        Args:\n",
    "            num_obs (int): Number of observations (time steps) in the entire \n",
    "                           dataset for which indices must be generated, e.g. \n",
    "                           len(data)\n",
    "\n",
    "            window_size (int): The desired length of each sub-sequence. Should be\n",
    "                               (input_sequence_length + target_sequence_length)\n",
    "                               E.g. if you want the model to consider the past 100\n",
    "                               time steps in order to predict the future 50 \n",
    "                               time steps, window_size = 100+50 = 150\n",
    "\n",
    "            step_size (int): Size of each step as the data sequence is traversed \n",
    "                             by the moving window.\n",
    "                             If 1, the first sub-sequence will be [0:window_size], \n",
    "                             and the next will be [1:window_size].\n",
    "\n",
    "        Return:\n",
    "            indices: a list of tuples\n",
    "        \"\"\"\n",
    "\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Showing how to use the model with some time series data.\n",
    "\n",
    "NB! This is not a full training loop. You have to write the training loop yourself. \n",
    "\n",
    "I.e. this code is just a starting point to show you how to initialize the model and provide its inputs\n",
    "\n",
    "If you do not know how to train a PyTorch model, it is too soon for you to dive into transformers imo :) \n",
    "\n",
    "You're better off starting off with some simpler architectures, e.g. a simple feed forward network, \n",
    "in order to learn the basics\n",
    "\"\"\"\n",
    "\n",
    "# Hyperparams\n",
    "test_size = 0.1\n",
    "batch_size = 32\n",
    "target_col_name = \"Normalized Demand\"\n",
    "timestamp_col = \"timestamp\"\n",
    "# Only use data from this date and onwards\n",
    "cutoff_date = datetime.datetime(2017, 1, 1) \n",
    "\n",
    "## Params\n",
    "dim_val = 64 #512\n",
    "n_heads = 4 #8\n",
    "n_decoder_layers = 2#4\n",
    "n_encoder_layers = 2#4\n",
    "dec_seq_len = 32 # length of input given to decoder\n",
    "enc_seq_len = 32 # length of input given to encoder\n",
    "output_sequence_length = 12 # target sequence length. If hourly data and length = 48, you predict 2 days ahead\n",
    "window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n",
    "step_size = 1 # Step size, i.e. how many time steps does the moving window move at each step\n",
    "in_features_encoder_linear_layer = 128 #2048\n",
    "in_features_decoder_linear_layer = 128 #2048\n",
    "max_seq_len = enc_seq_len\n",
    "batch_first = False\n",
    "\n",
    "# Define input variables \n",
    "exogenous_vars = [] # should contain strings. Each string must correspond to a column name\n",
    "input_variables = [target_col_name] + exogenous_vars\n",
    "target_idx = 0 # index position of target in batched trg_y\n",
    "\n",
    "input_size = len(input_variables)\n",
    "\n",
    "# Read data\n",
    "path = \"/Users/aidanwiteck/Desktop/Princeton/Year 4/Thesis/electricgrid/data/final_tables/banc/banc.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Z-score normalization\n",
    "mean_demand = df['Demand (MWh)'].mean()\n",
    "std_demand = df['Demand (MWh)'].std()\n",
    "\n",
    "df['Normalized Demand'] = (df['Demand (MWh)'] - mean_demand) / std_demand\n",
    "data = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From get_src_trg: data size = torch.Size([59206, 1])\n"
     ]
    }
   ],
   "source": [
    "# Remove test data from dataset\n",
    "training_data = data[:-(round(len(data)*test_size))]\n",
    "# Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n",
    "# Should be training data indices only\n",
    "training_indices = get_indices_entire_sequence(\n",
    "    data=training_data, \n",
    "    window_size=window_size, \n",
    "    step_size=step_size)\n",
    "\n",
    "# Making instance of custom dataset class\n",
    "training_data = TransformerDataset(\n",
    "    data=torch.tensor(training_data[input_variables].values).float(),\n",
    "    indices=training_indices,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    dec_seq_len=dec_seq_len,\n",
    "    target_seq_len=output_sequence_length\n",
    "    )\n",
    "\n",
    "# Making dataloader\n",
    "training_data = DataLoader(training_data, batch_size)\n",
    "i, batch = next(enumerate(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape changed from torch.Size([32, 32, 1]) to torch.Size([32, 32, 1])\n",
      "trg shape changed from torch.Size([32, 12, 1]) to torch.Size([12, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "src, trg, trg_y = batch\n",
    "\n",
    "# Permute from shape [batch size, seq len, num features] to [seq len, batch size, num features]\n",
    "if batch_first == False:\n",
    "\n",
    "    shape_before = src.shape\n",
    "    src = src.permute(1, 0, 2)\n",
    "    print(\"src shape changed from {} to {}\".format(shape_before, src.shape))\n",
    "\n",
    "    shape_before = trg.shape\n",
    "    trg = trg.permute(1, 0, 2)\n",
    "    print(\"trg shape changed from {} to {}\".format(shape_before, trg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidanwiteck/.virtualenvs/thesis/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer(\n",
    "    input_size=len(input_variables),\n",
    "    dec_seq_len=enc_seq_len,\n",
    "    batch_first=batch_first,\n",
    "    num_predicted_features=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make src mask for decoder with size:\n",
    "# [batch_size*n_heads, output_sequence_length, enc_seq_len]\n",
    "src_mask = generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length,\n",
    "    dim2=enc_seq_len\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tgt mask for decoder with size:\n",
    "# [batch_size*n_heads, output_sequence_length, output_sequence_length]\n",
    "tgt_mask = generate_square_subsequent_mask( \n",
    "    dim1=output_sequence_length,\n",
    "    dim2=output_sequence_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function, Optimizer and Model\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 1849/1849 [3:42:24<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.0173\n",
      "1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1849/1849 [17:34:35<00:00, 34.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 1.0135\n",
      "1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 1849/1849 [25:43<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 1.0085\n",
      "1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 1849/1849 [28:47<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 1.0046\n",
      "1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 1849/1849 [32:26<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()  # set the model to training mode\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    print(len(training_data))\n",
    "    for batch_idx, batch in enumerate(tqdm(training_data)):\n",
    "#         print(f\"batch_idx: {batch_idx}\")\n",
    "        src, trg, trg_y = batch\n",
    "        \n",
    "#         print(src.shape, trg.shape, trg_y.shape)\n",
    "\n",
    "        # If your data isn't on the GPU yet, you'll need to send it there\n",
    "        src = src.to(device)  # 'device' could be 'cuda' or 'cpu'\n",
    "        trg = trg.to(device)\n",
    "        trg_y = trg_y.to(device)\n",
    "        \n",
    "#         print(\"to device\")\n",
    "        # Permute if necessary\n",
    "        if batch_first == False:\n",
    "            src = src.permute(1, 0, 2)\n",
    "            trg = trg.permute(1, 0, 2)\n",
    "            trg_y = trg_y.permute(1,0)\n",
    "\n",
    "        # Zero the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Model forward pass\n",
    "        output = model(src=src, tgt=trg, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "#         print(\"Got output\")\n",
    "        \n",
    "        # Compute loss\n",
    "#         print(output.shape, trg_y.shape)\n",
    "        output = output.squeeze(-1)\n",
    "        loss = criterion(output, trg_y)\n",
    "#         print(\"Got loss\")\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "#         print(\"Backward\")\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "#         print(\"Step\")\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    avg_epoch_loss = epoch_loss / len(training_data)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "    src=src,\n",
    "    tgt=trg,\n",
    "    src_mask=src_mask,\n",
    "    tgt_mask=tgt_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 26, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path,  timestamp_col_name: str=\"timestamp\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read data from csv file and return pd.Dataframe object\n",
    "\n",
    "    Args:\n",
    "\n",
    "        data_dir: str or Path object specifying the path to the directory \n",
    "                  containing the data\n",
    "\n",
    "        target_col_name: str, the name of the column containing the target variable\n",
    "\n",
    "        timestamp_col_name: str, the name of the column or named index \n",
    "                            containing the timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Reading file in {}\".format(data_path))\n",
    "\n",
    "    data = pd.read_csv(\n",
    "        data_path, \n",
    "        parse_dates=[timestamp_col_name], \n",
    "        index_col=[timestamp_col_name], \n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False\n",
    "    )\n",
    "\n",
    "    data = to_numeric_and_downcast_data(data)\n",
    "\n",
    "    # Make sure data is in ascending order by timestamp\n",
    "    data.sort_values(by=[timestamp_col_name], inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
